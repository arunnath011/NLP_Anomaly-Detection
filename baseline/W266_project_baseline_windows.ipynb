{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy1hA1l8YlTb",
        "outputId": "ba19a4dd-ef0a-478a-85d9-218e9cb553b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "os.environ=environ({'NV_LIBCUBLAS_DEV_VERSION': '11.4.1.1043-1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-2', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.1.1.33-1+cuda11.2', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.8.4-1+cuda11.2', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.19', 'CLOUDSDK_PYTHON': 'python3', 'LANG': 'en_US.UTF-8', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-11-2=11.3.2.152-1', 'HOSTNAME': '6520f85c6062', 'OLDPWD': '/', 'CLOUDSDK_CONFIG': '/content/.config', 'KMP_EXTRA_ARGS': '--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/m-s-1bxokgywbt81t --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true', 'NV_LIBNPP_VERSION': '11.3.2.152-1', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-11-2=11.2.152-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'NV_NVPROF_VERSION': '11.2.152-1', 'NV_LIBCUSPARSE_VERSION': '11.4.1.1152-1', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.12\",\"jupyterArgs\":[\"--ip=172.28.0.12\",\"--transport=ipc\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-11-2=11.4.1.1043-1', 'ENV': '/root/.bashrc', 'NCCL_VERSION': '2.8.4-1', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'NO_GCE_CHECK': 'False', 'PWD': '/', 'NVARCH': 'x86_64', 'HOME': '/root', 'NV_LIBCUSPARSE_DEV_VERSION': '11.4.1.1152-1', 'KMP_LISTEN_PORT': '6000', 'LAST_FORCED_REBUILD': '20221121', 'NV_LIBNCCL_PACKAGE_VERSION': '2.8.4-1', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.8.4-1+cuda11.2', 'DEBIAN_FRONTEND': 'noninteractive', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'NV_CUDA_LIB_VERSION': '11.2.2-1', 'NV_LIBNPP_PACKAGE': 'libnpp-11-2=11.3.2.152-1', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_NVTX_VERSION': '11.2.152-1', 'NV_LIBCUBLAS_VERSION': '11.4.1.1043-1', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-11-2=11.4.1.1043-1', 'GCE_METADATA_TIMEOUT': '3', 'NV_CUDNN_VERSION': '8.1.1.33', 'VM_GCE_METADATA_HOST': '169.254.169.253', 'NV_CUDA_CUDART_DEV_VERSION': '11.2.152-1', 'KMP_TARGET_PORT': '9000', 'GLIBCPP_FORCE_NEW': '1', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'SHELL': '/bin/bash', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVML_DEV_VERSION': '11.2.152-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'CUDA_VERSION': '11.2.2', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-11-2', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'SHLVL': '0', 'PYTHONPATH': '/env/python', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-11-2', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.2 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=450,driver<451', 'NV_LIBNPP_DEV_VERSION': '11.3.2.152-1', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'NV_CUDA_CUDART_VERSION': '11.2.152-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'GLIBCXX_FORCE_NEW': '1', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.8.4-1', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.1.1.33-1+cuda11.2', 'JPY_PARENT_PID': '60', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'ENABLE_DIRECTORYPREFETCHER': '1', 'USE_AUTH_EPHEM': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO'})\n",
            "sys.argv=['/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-d25620be-b3fd-442f-b334-f2e1315a4cad.json']\n",
            "MLFLOW_TRACKING_URINone\n",
            "sys.executable=/usr/bin/python3\n",
            "sys.path=['/content', '/env/python', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.8/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "#getting all the packages\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(f'os.environ={os.environ}')\n",
        "print(f'sys.argv={sys.argv}')\n",
        "print(f\"MLFLOW_TRACKING_URI{os.environ.get('MLFLOW_TRACKING_URI')}\")\n",
        "print(f\"sys.executable={sys.executable}\")\n",
        "print(f\"sys.path={sys.path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vScCBsIesEyQ",
        "outputId": "d84cc0d4-18bc-4964-aae1-25713560d27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIPeNCBGY4J6",
        "outputId": "0f3c0736-4915-4d3a-8515-e72ac1e46f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'logbert'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 130 (delta 9), reused 5 (delta 5), pack-reused 90\u001b[K\n",
            "Receiving objects: 100% (130/130), 210.44 KiB | 7.01 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "! rm -rf  logbert\n",
        "! git clone https://github.com/HelenGuohx/logbert.git\n",
        "! pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Sbdol8j31Eiy"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/logbert/')\n",
        "from loglizer.models import InvariantsMiner, PCA, IsolationForest, OneClassSVM, LogClustering, LR, SVM\n",
        "from loglizer import dataloader, preprocessing\n",
        "from loglizer.utils import metrics\n",
        "from logdeep.dataset.session import sliding_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AOwXFIGfaWsA"
      },
      "outputs": [],
      "source": [
        "#%cd logbert\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBLquuj31w1M",
        "outputId": "43b0f2cb-4663-475a-f4a7-511f11229d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== Transformed train data summary ======\n",
            "Train data shape: 63972-by-86\n",
            "\n",
            "====== Transformed test data summary ======\n",
            "Test data shape: 7997-by-86\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train test split \n",
        "ouput_dir = \"/content/gdrive/MyDrive/Windows/\"\n",
        "middle_dir = \"\"\n",
        "log_file = \"/content/gdrive/MyDrive/Windows/Windows_log_labeled.csv\"\n",
        "\n",
        "train_ratio = 0.80\n",
        "test_ratio = 0.10\n",
        "validation_ratio = 0.10\n",
        "df=pd.read_csv(log_file)\n",
        "whole_data_emb = df[\"Content\"].values\n",
        "whole_data_label=df[\"Label\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(whole_data_emb, whole_data_label, test_size=test_ratio, random_state=1)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=validation_ratio/(train_ratio+test_ratio))\n",
        "\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = dataloader.load_data(ouput_dir, middle_dir, log_file, is_mapping=True)\n",
        "feature_extractor = preprocessing.FeatureExtractor()\n",
        "x_train = feature_extractor.fit_transform(x_train)\n",
        "x_test = feature_extractor.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IrcMixOTAyD",
        "outputId": "b9425695-5947-4c62-a217-e89f7b871ea1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 5., 3., 7., 2., 5., 1., 5., 2., 2., 3., 1., 0., 1., 3., 3., 1.,\n",
              "       0., 4., 2., 2., 1., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_train[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry2qklzm3qvu",
        "outputId": "52df42e6-e833-4a7c-ed99-5c8a5cd5cb0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: PCA ====================\n",
            "theshold 0\n",
            "====== Model summary ======\n",
            "n_components: 1\n",
            "Project matrix shape: 86-by-86\n",
            "SPE threshold: 1\n",
            "\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 4422, FP: 59550, TN: 0, FN: 0\n",
            "Precision: 6.912%, recall: 100.000%, F1-measure: 12.931%\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 553, FP: 7444, TN: 0, FN: 0\n",
            "Precision: 6.915%, recall: 100.000%, F1-measure: 12.936%\n",
            "\n",
            "CPU times: user 548 ms, sys: 85 ms, total: 633 ms\n",
            "Wall time: 557 ms\n"
          ]
        }
      ],
      "source": [
        "#PCA analysis\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: PCA \" + \"=\"*20)\n",
        "for th in np.arange(1):\n",
        "    print(\"theshold\", th)\n",
        "    model = PCA(n_components=0.8, threshold=1, c_alpha = 1.9600)\n",
        "    model.fit(x_train)\n",
        "    print('Train validation:')\n",
        "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "    print('Test validation:')\n",
        "    precision, recall, f1 = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqE3usbo5XAI",
        "outputId": "54fe5286-8650-45b2-e031-dd4d06b1faef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: IsolationForest ====================\n",
            "====== Model summary ======\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 4422, FP: 4093, TN: 55457, FN: 0\n",
            "Precision: 51.932, recall: 100.000, F1-measure: 68.362\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 553, FP: 487, TN: 6957, FN: 0\n",
            "Precision: 53.173, recall: 100.000, F1-measure: 69.429\n",
            "\n",
            "CPU times: user 8.11 s, sys: 184 ms, total: 8.3 s\n",
            "Wall time: 8.3 s\n"
          ]
        }
      ],
      "source": [
        "#isolation forest\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: IsolationForest \" + \"=\"*20)\n",
        "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=19)\n",
        "model.fit(x_train)\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Ey_Foh5nXd",
        "outputId": "6600c0df-6684-4e84-cb12-d5c069cef97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: one class SVM ====================\n",
            "====== Model summary ======\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/logbert/loglizer/utils.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  f1 = 2 * precision * recall / (precision + recall)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: TP: 0, FP: 59550, TN: 0, FN: 4422\n",
            "Precision: 0.000, recall: 0.000, F1-measure: nan\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 0, FP: 7444, TN: 0, FN: 553\n",
            "Precision: 0.000, recall: 0.000, F1-measure: nan\n",
            "\n",
            "CPU times: user 15min 52s, sys: 1.32 s, total: 15min 53s\n",
            "Wall time: 15min 53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/logbert/loglizer/utils.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  f1 = 2 * precision * recall / (precision + recall)\n"
          ]
        }
      ],
      "source": [
        "#SVM\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: one class SVM \" + \"=\"*20)\n",
        "model = OneClassSVM(kernel='rbf')\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbqm67Ti7rlJ",
        "outputId": "27786401-5a29-4935-94ef-2b8a4b24a586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: LogClustering ====================\n",
            "====== Model summary ======\n",
            "Starting offline clustering...\n",
            "Processed 1000 instances.\n",
            "Found 7 clusters offline.\n",
            "\n",
            "Starting online clustering...\n",
            "Processed 2000 instances.\n",
            "Processed 4000 instances.\n",
            "Processed 6000 instances.\n",
            "Processed 8000 instances.\n",
            "Processed 10000 instances.\n",
            "Processed 12000 instances.\n",
            "Processed 14000 instances.\n",
            "Processed 16000 instances.\n",
            "Processed 18000 instances.\n",
            "Processed 20000 instances.\n",
            "Processed 22000 instances.\n",
            "Processed 24000 instances.\n",
            "Processed 26000 instances.\n",
            "Processed 28000 instances.\n",
            "Processed 30000 instances.\n",
            "Processed 32000 instances.\n",
            "Processed 34000 instances.\n",
            "Processed 36000 instances.\n",
            "Processed 38000 instances.\n",
            "Processed 40000 instances.\n",
            "Processed 42000 instances.\n",
            "Processed 44000 instances.\n",
            "Processed 46000 instances.\n",
            "Processed 48000 instances.\n",
            "Processed 50000 instances.\n",
            "Processed 52000 instances.\n",
            "Processed 54000 instances.\n",
            "Processed 56000 instances.\n",
            "Processed 58000 instances.\n",
            "Processed 59550 instances.\n",
            "Found 9 clusters online.\n",
            "\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 2098, FP: 0, TN: 59550, FN: 2324\n",
            "Precision: 100.000, recall: 47.445, F1-measure: 64.356\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 273, FP: 0, TN: 7444, FN: 280\n",
            "Precision: 100.000, recall: 49.367, F1-measure: 66.102\n",
            "\n",
            "CPU times: user 21.2 s, sys: 592 ms, total: 21.8 s\n",
            "Wall time: 21.3 s\n"
          ]
        }
      ],
      "source": [
        "#Clustering\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: LogClustering \" + \"=\"*20)\n",
        "max_dist = 0.3  # the threshold to stop the clustering process\n",
        "anomaly_threshold = 0.3  # the threshold for anomaly detection\n",
        "model = LogClustering(max_dist=max_dist, anomaly_threshold=anomaly_threshold)\n",
        "model.fit(x_train[y_train == 0, :])  # Use only normal samples for training\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}