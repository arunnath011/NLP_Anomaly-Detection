{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy1hA1l8YlTb",
        "outputId": "7f68d223-2412-45b9-cfec-60005169a8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "os.environ=environ({'NV_LIBCUBLAS_DEV_VERSION': '11.4.1.1043-1', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-2', 'NV_CUDNN_PACKAGE_DEV': 'libcudnn8-dev=8.1.1.33-1+cuda11.2', 'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64', 'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.8.4-1+cuda11.2', 'TCLLIBPATH': '/usr/share/tcltk/tcllib1.19', 'CLOUDSDK_PYTHON': 'python3', 'LANG': 'en_US.UTF-8', 'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-11-2=11.3.2.152-1', 'HOSTNAME': '613edc38c773', 'OLDPWD': '/', 'CLOUDSDK_CONFIG': '/content/.config', 'NV_LIBNPP_VERSION': '11.3.2.152-1', 'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-11-2=11.2.152-1', 'NVIDIA_VISIBLE_DEVICES': 'all', 'NV_NVPROF_VERSION': '11.2.152-1', 'NV_LIBCUSPARSE_VERSION': '11.4.1.1152-1', 'DATALAB_SETTINGS_OVERRIDES': '{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=172.28.0.2\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}', 'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-11-2=11.4.1.1043-1', 'ENV': '/root/.bashrc', 'NCCL_VERSION': '2.8.4-1', 'TF_FORCE_GPU_ALLOW_GROWTH': 'true', 'NO_GCE_CHECK': 'False', 'PWD': '/', 'NVARCH': 'x86_64', 'HOME': '/root', 'NV_LIBCUSPARSE_DEV_VERSION': '11.4.1.1152-1', 'KMP_LISTEN_PORT': '6000', 'LAST_FORCED_REBUILD': '20221021', 'NV_LIBNCCL_PACKAGE_VERSION': '2.8.4-1', 'NV_LIBNCCL_PACKAGE': 'libnccl2=2.8.4-1+cuda11.2', 'DEBIAN_FRONTEND': 'noninteractive', 'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev', 'NV_CUDA_LIB_VERSION': '11.2.2-1', 'NV_LIBNPP_PACKAGE': 'libnpp-11-2=11.3.2.152-1', 'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2', 'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs', 'NV_NVTX_VERSION': '11.2.152-1', 'NV_LIBCUBLAS_VERSION': '11.4.1.1043-1', 'NV_LIBCUBLAS_PACKAGE': 'libcublas-11-2=11.4.1.1043-1', 'GCE_METADATA_TIMEOUT': '3', 'NV_CUDNN_VERSION': '8.1.1.33', 'VM_GCE_METADATA_HOST': '169.254.169.254', 'NV_CUDA_CUDART_DEV_VERSION': '11.2.152-1', 'KMP_TARGET_PORT': '9000', 'GLIBCPP_FORCE_NEW': '1', 'TBE_CREDS_ADDR': '172.28.0.1:8008', 'SHELL': '/bin/bash', 'GCS_READ_CACHE_BLOCK_SIZE_MB': '16', 'NV_NVML_DEV_VERSION': '11.2.152-1', 'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command', 'CUDA_VERSION': '11.2.2', 'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-11-2', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'TBE_RUNTIME_ADDR': '172.28.0.1:8011', 'SHLVL': '0', 'PYTHONPATH': '/env/python', 'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-11-2', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.2 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=450,driver<451', 'NV_LIBNPP_DEV_VERSION': '11.3.2.152-1', 'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009', 'NV_CUDA_CUDART_VERSION': '11.2.152-1', 'NV_CUDNN_PACKAGE_NAME': 'libcudnn8', 'GLIBCXX_FORCE_NEW': '1', 'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin', 'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.8.4-1', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4', 'NV_CUDNN_PACKAGE': 'libcudnn8=8.1.1.33-1+cuda11.2', 'JPY_PARENT_PID': '59', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', 'ENABLE_DIRECTORYPREFETCHER': '1', 'USE_AUTH_EPHEM': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO'})\n",
            "sys.argv=['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-3f9d993b-538b-4800-b3d1-e02bc9e0dc63.json']\n",
            "MLFLOW_TRACKING_URINone\n",
            "sys.executable=/usr/bin/python3\n",
            "sys.path=['/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "#getting all the packages\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(f'os.environ={os.environ}')\n",
        "print(f'sys.argv={sys.argv}')\n",
        "print(f\"MLFLOW_TRACKING_URI{os.environ.get('MLFLOW_TRACKING_URI')}\")\n",
        "print(f\"sys.executable={sys.executable}\")\n",
        "print(f\"sys.path={sys.path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover the baseline model buuilding for the Thunderbird dataset, we will cover the following algorithm for the baseline model \n",
        "1.)PCA- principal component analysis, \n",
        "2.)One-Class SVM- commonly used one-class classification model and commonplace in log anomaly detection \n",
        "3.)Isolation Forest -  this algorithm uses an unsupervised methodology for anomaly detection using features as tree structure\n"
      ],
      "metadata": {
        "id": "PY7USTo3Dfwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vScCBsIesEyQ",
        "outputId": "259eb3cb-575b-4b7c-c369-864d4aa2d14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gtG5lskvEohI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the logbert github for dataparsing and baseline analysis, https://github.com/HelenGuohx/logbert.git"
      ],
      "metadata": {
        "id": "guOYiEaKEaNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "! git clone https://github.com/HelenGuohx/logbert.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIPeNCBGY4J6",
        "outputId": "027f724d-e07c-4af5-a4c9-fd17d1dbdd36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'logbert'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 130 (delta 9), reused 5 (delta 5), pack-reused 90\u001b[K\n",
            "Receiving objects: 100% (130/130), 210.44 KiB | 6.58 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/logbert/')\n",
        "from loglizer.models import InvariantsMiner, PCA, IsolationForest, OneClassSVM, LogClustering, LR, SVM\n",
        "from loglizer import dataloader, preprocessing\n",
        "from loglizer.utils import metrics\n",
        "from logdeep.dataset.session import sliding_window"
      ],
      "metadata": {
        "id": "Sbdol8j31Eiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd logbert\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import svm\n",
        "from sklearn.utils import shuffle\n",
        "\n"
      ],
      "metadata": {
        "id": "AOwXFIGfaWsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split \n",
        "ouput_dir = \"/content/gdrive/MyDrive/W266_Final_Project/Tbird parsed/\"\n",
        "middle_dir = \"\"\n",
        "log_file = \"Thunderbird_20M.log\"\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = dataloader.load_data(ouput_dir, middle_dir, log_file, is_mapping=True)\n",
        "feature_extractor = preprocessing.FeatureExtractor()\n",
        "x_train = feature_extractor.fit_transform(x_train)\n",
        "x_test = feature_extractor.transform(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBLquuj31w1M",
        "outputId": "66e8d0bf-1e8b-4990-dd49-bc0fafd79298"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/logbert/loglizer/dataloader.py:286: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train = np.array(train).reshape(-1,1)\n",
            "/content/logbert/loglizer/dataloader.py:292: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  test_normal = np.array(test_normal).reshape(-1,1)\n",
            "/content/logbert/loglizer/dataloader.py:298: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  abnormal = np.array(abnormal).reshape(-1,1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train normal size: 6000\n",
            "Train abnormal size: 3000\n",
            "Total logkey(exclude 0:UNK) 1206\n",
            "Test normal size: 71155\n",
            "Test abnormal size: 42385\n",
            "num_unk_event in test data: 0\n",
            "====== Transformed train data summary ======\n",
            "Train data shape: 9000-by-921\n",
            "\n",
            "====== Transformed test data summary ======\n",
            "Test data shape: 113540-by-921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IrcMixOTAyD",
        "outputId": "ce138408-457e-4ba6-deaa-998f6dd69387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 5., 3., 8., 4., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 5., 4., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA analysis\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: PCA \" + \"=\"*20)\n",
        "for th in np.arange(1):\n",
        "    print(\"theshold\", th)\n",
        "    model = PCA(n_components=0.8, threshold=1, c_alpha = 1.9600)\n",
        "    model.fit(x_train)\n",
        "    print('Train validation:')\n",
        "    precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "    print('Test validation:')\n",
        "    precision, recall, f1 = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry2qklzm3qvu",
        "outputId": "e71cdef5-fb18-43cb-c7a4-807073c49d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: PCA ====================\n",
            "theshold 0\n",
            "====== Model summary ======\n",
            "n_components: 5\n",
            "Project matrix shape: 921-by-921\n",
            "SPE threshold: 1\n",
            "\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 3000, FP: 5996, TN: 4, FN: 0\n",
            "Precision: 33.348%, recall: 100.000%, F1-measure: 50.017%\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 42385, FP: 71091, TN: 64, FN: 0\n",
            "Precision: 37.352%, recall: 100.000%, F1-measure: 54.388%\n",
            "\n",
            "CPU times: user 34.4 s, sys: 2.75 s, total: 37.1 s\n",
            "Wall time: 19.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#isolation forest\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: IsolationForest \" + \"=\"*20)\n",
        "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=19)\n",
        "model.fit(x_train)\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqE3usbo5XAI",
        "outputId": "a51f5822-b1af-4dcc-ce41-0e81cc48f350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: IsolationForest ====================\n",
            "====== Model summary ======\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 49, FP: 104, TN: 5896, FN: 2951\n",
            "Precision: 32.026, recall: 1.633, F1-measure: 3.108\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 686, FP: 1297, TN: 69858, FN: 41699\n",
            "Precision: 34.594, recall: 1.619, F1-measure: 3.092\n",
            "\n",
            "CPU times: user 35.7 s, sys: 8.31 s, total: 44 s\n",
            "Wall time: 44 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: one class SVM \" + \"=\"*20)\n",
        "model = OneClassSVM(kernel='rbf')\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Ey_Foh5nXd",
        "outputId": "76c6e0b0-b20b-4b8b-d53d-46f7935642ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: one class SVM ====================\n",
            "====== Model summary ======\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 976, FP: 6000, TN: 0, FN: 2024\n",
            "Precision: 13.991, recall: 32.533, F1-measure: 19.567\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 14728, FP: 71155, TN: 0, FN: 27657\n",
            "Precision: 17.149, recall: 34.748, F1-measure: 22.964\n",
            "\n",
            "CPU times: user 8min 38s, sys: 631 ms, total: 8min 39s\n",
            "Wall time: 8min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clustering\n",
        "%%time\n",
        "print(\"=\"*20 + \" Model: LogClustering \" + \"=\"*20)\n",
        "max_dist = 0.3  # the threshold to stop the clustering process\n",
        "anomaly_threshold = 0.3  # the threshold for anomaly detection\n",
        "model = LogClustering(max_dist=max_dist, anomaly_threshold=anomaly_threshold)\n",
        "model.fit(x_train[y_train == 0, :])  # Use only normal samples for training\n",
        "print('Train validation:')\n",
        "precision, recall, f1 = model.evaluate(x_train, y_train)\n",
        "print('Test validation:')\n",
        "precision, recall, f1 = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbqm67Ti7rlJ",
        "outputId": "47132595-b6f7-4543-fcca-5cecb48b32cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Model: LogClustering ====================\n",
            "====== Model summary ======\n",
            "Starting offline clustering...\n",
            "Processed 1000 instances.\n",
            "Found 75 clusters offline.\n",
            "\n",
            "Starting online clustering...\n",
            "Processed 2000 instances.\n",
            "Processed 4000 instances.\n",
            "Processed 6000 instances.\n",
            "Processed 6000 instances.\n",
            "Found 110 clusters online.\n",
            "\n",
            "Train validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 1348, FP: 1, TN: 5999, FN: 1652\n",
            "Precision: 99.926, recall: 44.933, F1-measure: 61.991\n",
            "\n",
            "Test validation:\n",
            "====== Evaluation summary ======\n",
            "Confusion Matrix: TP: 19242, FP: 376, TN: 70779, FN: 23143\n",
            "Precision: 98.083, recall: 45.398, F1-measure: 62.068\n",
            "\n",
            "CPU times: user 2min 53s, sys: 713 ms, total: 2min 54s\n",
            "Wall time: 2min 54s\n"
          ]
        }
      ]
    }
  ]
}